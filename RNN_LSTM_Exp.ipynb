{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaykumarharakuni/Deeplearning/blob/main/RNN_LSTM_Exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Classification using RNN & LSTM -Moview Review Classification Project"
      ],
      "metadata": {
        "id": "YMHYM2YkvpNr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDF_Y6t0vAWA"
      },
      "outputs": [],
      "source": [
        "# Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load the dataset"
      ],
      "metadata": {
        "id": "aTYgiJD1wbCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "\n",
        "dataset_path='/content/drive/MyDrive/NLP/Datasets/Lesson_6/aclImdb_v1.tar.gz'\n",
        "\n",
        "# extract the dataset\n",
        "with tarfile.open(dataset_path) as f:\n",
        "    f.extractall()\n",
        "\n",
        "print('Data Extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CRGFVEpwcGa",
        "outputId": "e2727cd4-c529-4f7f-8d5d-04130f546d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Paths to the training data\n",
        "train_dir = 'aclImdb/train'\n",
        "\n",
        "# Load reviews and labels\n",
        "def load_reviews(directory):\n",
        "    reviews = []\n",
        "    labels = []\n",
        "\n",
        "    for label_type in ['pos', 'neg']:\n",
        "        dir_name = os.path.join(directory, label_type)\n",
        "        for fname in os.listdir(dir_name):\n",
        "            if fname.endswith('.txt'):\n",
        "                with open(os.path.join(dir_name, fname), 'r', encoding='utf-8') as f:\n",
        "                    reviews.append(f.read())\n",
        "                labels.append(1 if label_type == 'pos' else 0)\n",
        "\n",
        "    return reviews, labels\n",
        "\n",
        "# Load training data\n",
        "train_reviews, train_labels = load_reviews(train_dir)\n",
        "\n",
        "# Convert labels to numpy array\n",
        "train_labels = np.array(train_labels)"
      ],
      "metadata": {
        "id": "2CPH7jHUwweS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total train reviews\n",
        "len(train_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NskvQVAx6oS",
        "outputId": "8ad1bee3-1f90-49a9-9607-830266746313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train labels length\n",
        "len(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCRIta9yx9iD",
        "outputId": "3d600c4f-7a2f-4382-9d81-67c2dd9bf3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_reviews[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9d9DiFIyFBe",
        "outputId": "65efa984-66fe-495d-a259-6230f642eecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Gandhi, the Great :<br /><br />Greatness in the world is associated with people like Alexanader the great, Ashoka the Great for their greatness lied in being glorified as more than humans. Gandhi is called great for actually not being a Great but being more human, for I always believe bringing out the humanity in us is where the greatness of being human lies.Gandhi was a human with humanity and one who strived for humanity ready to sacrifice himself in the battle for humanity but not his enemies. Let me move to the movie review now.<br /><br />About Gandhi My Father :<br /><br />Gandhi My father is a film not about Gandhi but about his son Harilal Gandhi.On telling the story of a son whose father was one of the greatest humans to walk this earth, the director succeeds in portraying the tale.The film succeeds in telling the story of a mislead son of a father who lead a nation to greatness.The movie is termed as a criticism of Gandhi's failure as a father to his son, I would rather say it is of a sacrifice Gandhi had made as a father of a son to do justice as a father of a nation.<br /><br />I wish the essence of this movie prevails not just in India, the Gandhian land, but through the hearts of all the people of this world.<br /><br />Gandhi the true Human. Jaihind.\",\n",
              " \"Well, it definitely is unlike anything else directed by Lynch. No supernatural stuff, no violence, no profanity. Nevertheless, it is a beautiful flick. It's a little slow but perhaps that was intentional because it's the story of an old man's 6-week(that's my best guess for its duration) journey. The characters are everyday people and thus, they are believable. The performances are good and the final scene was incredibly touching. Everyone who has a sibling can relate to it. Lyle and Alvin don't even have to say anything. For a moment they are back in the old days and all the fighting is forgotten.\",\n",
              " 'THE LADY FROM SHANGHAI is proof that the great genius Orson Welles could direct a \"mainstream\" movie if he wanted to. By comparison to his other, more artistic works, this film has only a moderate amount of craftiness, and almost no esoteric elements.<br /><br />The exception being, of course, the final scene in the hall of mirrors, widely agreed to be one of the greatest scenes in the history of film. It alone is worth the cost of a rental.<br /><br />The sweet surprise was the superb acting by the beautiful Rita Hayworth. Her acting during the beginning and middle of the film is so excellent, she made the other actors appear as caricatures instead of characters. Even the great Mr. Welles.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the data into vectors"
      ],
      "metadata": {
        "id": "9srxg4WZ0CiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize & create sequences"
      ],
      "metadata": {
        "id": "JRl3_DH80KC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_words=20000 # limit the vocab size\n",
        "max_len=200 # max len for each review\n"
      ],
      "metadata": {
        "id": "ASknWTCTyZT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print('imported')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faWEqm4k0XfC",
        "outputId": "35060629-3c92-4ec0-9fa3-5b6d4d9be01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train_reviews)"
      ],
      "metadata": {
        "id": "qZPOu77J0nZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sequences\n",
        "train_sequences=tokenizer.texts_to_sequences(train_reviews)\n",
        "train_data=pad_sequences(train_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "epehYd3-02Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train data shape',train_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXF-JcaR1E0q",
        "outputId": "407b74b7-167a-404f-dfb7-3b4ea4b22c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape (25000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcTxcX4f1LRu",
        "outputId": "b587f1d5-d959-48a5-baa4-1e9e0f671e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "          22,    37,     5,  3310,  4138,    22,    37,  1311,    11,\n",
              "           6,    15,    22,   526,  1092,    17,    31,  4801,   489,\n",
              "           4,     3,  2553,   780,  2270,  4011,  5745,  4844,     2,\n",
              "        1092,   799,     6,     1,   678,     4,  2297,  1670,    31,\n",
              "        2354,   868,     8,     1,   482,   214,     7,     7,     1,\n",
              "         111,     6,    41,  6259, 16115,     8,    24,  7180,    34,\n",
              "          40,  9259,    53,    36,     3,  7181,   100,   109,    31,\n",
              "        1838,  1853, 16115,     6,  2512,     5,   374,    34,   566,\n",
              "          87,    14,    26,    13,   274,     3,    20,     1,  1314,\n",
              "         466,     1,  2512,    26,    44,   911,  1992,     2,     9,\n",
              "         183,    37,   139,   559,   117,    87,     7,     7,    21,\n",
              "        3626,    18,    52,  1391,     2,    70,   253,    17,    10,\n",
              "          25,    58,    20,     1,   274,    10,   101,     1,  1392,\n",
              "        2161,     1,  1699,    18,    11,   274,    13,   906,     5,\n",
              "          98,  8776,     7,     7,    10,  2297,   383,     9,   785,\n",
              "         454,   155], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "9EQ7ck952RG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab['world']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2bAzfC02lbt",
        "outputId": "7505a365-881a-4269-9972-f3141ab780d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zodbP0U62nyf",
        "outputId": "10ea51ae-a8b2-4cb8-903d-d459e9bc0e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dept names\n",
        "HR   0\n",
        "IT   1\n",
        "Fin  2"
      ],
      "metadata": {
        "id": "ErQQxcCK3xoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "zOCVyVJT4A_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from  tensorflow.keras.models import Sequential\n",
        "from  tensorflow.keras.layers import Embedding,SimpleRNN,Dense"
      ],
      "metadata": {
        "id": "Xts_9ZVO2t9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### captures the sementic relationship"
      ],
      "metadata": {
        "id": "X398y8aF5zFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model=Sequential([Embedding(max_words,128,input_length=max_len),\n",
        "                      SimpleRNN(64),\n",
        "                      Dense(1,activation='sigmoid')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdXdroVj4giJ",
        "outputId": "5db8bbf6-8ebe-4280-b0dc-40064d3523ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MemZLb2O48j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the model\n",
        "history=rnn_model.fit(train_data,train_labels,epochs=10,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFVJ-rA17sK5",
        "outputId": "49a52ab1-6d47-4dcd-f7ee-de476e5fb5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.6649 - loss: 0.6033 - val_accuracy: 0.7044 - val_loss: 0.6211\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8636 - loss: 0.3283 - val_accuracy: 0.5330 - val_loss: 1.0922\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9423 - loss: 0.1629 - val_accuracy: 0.7744 - val_loss: 0.6207\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9781 - loss: 0.0683 - val_accuracy: 0.6968 - val_loss: 1.0286\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9907 - loss: 0.0316 - val_accuracy: 0.5870 - val_loss: 1.6372\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9566 - loss: 0.1135 - val_accuracy: 0.7582 - val_loss: 0.7919\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.9530 - loss: 0.1246 - val_accuracy: 0.7108 - val_loss: 0.9487\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9722 - loss: 0.0787 - val_accuracy: 0.6556 - val_loss: 0.7808\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9281 - loss: 0.1880 - val_accuracy: 0.6958 - val_loss: 0.9139\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9125 - loss: 0.2214 - val_accuracy: 0.6464 - val_loss: 1.1357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test the model"
      ],
      "metadata": {
        "id": "J_ZzdIpU8tJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir='/content/aclImdb/test'\n",
        "test_reviews,test_labels=load_reviews(test_dir)\n",
        "test_labels=np.array(test_labels)\n",
        "\n",
        "test_sequences=tokenizer.texts_to_sequences(test_reviews)\n",
        "test_data=pad_sequences(test_sequences,maxlen=max_len)\n",
        "\n",
        "rnn_model.evaluate(test_data,test_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBWTRMno8ueA",
        "outputId": "5c812553-67cc-4fdc-8f01-c05ba388157e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.4795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7491519451141357, 0.7541199922561646]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=rnn_model.evaluate(test_data,test_labels)\n",
        "print('Test Accuracy',accuracy)\n",
        "print('Test Loss',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKhaQCjS9RSq",
        "outputId": "c19cefd1-eba9-46be-ee73-1300b7ca304f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.4795\n",
            "Test Accuracy 0.7541199922561646\n",
            "Test Loss 0.7491519451141357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=rnn_model.evaluate(train_data,train_labels)\n",
        "print('Train Accuracy',accuracy)\n",
        "print('Train Loss',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX8V7PVS9ryk",
        "outputId": "52e678d3-9a90-44d2-9ce3-951de35cdf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9634 - loss: 0.1094\n",
            "Train Accuracy 0.8917999863624573\n",
            "Train Loss 0.33019211888313293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new prediction"
      ],
      "metadata": {
        "id": "pnvx_l8d-kzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to preprocess input review and make predictions\n",
        "def predict_sentiment(review, model, tokenizer, max_len=200):\n",
        "    # Convert the review to a sequence of word indices\n",
        "    review_seq = tokenizer.texts_to_sequences([review])\n",
        "\n",
        "    # Pad the sequence to ensure it has the correct length\n",
        "    review_pad = pad_sequences(review_seq, maxlen=max_len)\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = model.predict(review_pad)\n",
        "\n",
        "    # Convert prediction to label (1: positive, 0: negative)\n",
        "    sentiment = 'Positive' if prediction >= 0.5 else 'Negative'\n",
        "\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Sentiment: {sentiment}\")\n",
        "    print(f\"Prediction score: {prediction[0][0]:.4f}\\n\")"
      ],
      "metadata": {
        "id": "WWfb1m289_1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_review = \"The movie was absolutely fantastic, with a great storyline and brilliant acting!\"\n",
        "predict_sentiment(new_review, rnn_model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RVS2iG1-oUY",
        "outputId": "347f33a4-fd2e-4643-cf7b-a03b191a7947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "Review: The movie was absolutely fantastic, with a great storyline and brilliant acting!\n",
            "Sentiment: Positive\n",
            "Prediction score: 0.9489\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "new_review = \"The movie was good\"\n",
        "predict_sentiment(new_review, rnn_model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KNMexO6-6Xx",
        "outputId": "e0afe3c9-81c6-4d2b-ca20-550cd5e500f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Review: The movie was good\n",
            "Sentiment: Positive\n",
            "Prediction score: 0.9917\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2bidd8V-8fR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}